{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "import yaml\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL=\"gpt-4o\"\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as an env var>\")\n",
    "DB_INDEX_FILE_LOCAL_PATH = os.environ.get(\"DB_INDEX_FILE_LOCAL_PATH\", \"<path to the index.json file>\")\n",
    "DB_ROOT_LOCAL_PATH = os.environ.get(\"DB_ROOT_LOCAL_PATH\", \"<path to the root directory of the database>\")\n",
    "\n",
    "openAiClient = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "with open(\"../prompts/memoryClassifier.yml\", \"r\") as file:\n",
    "    group_classifier = yaml.safe_load(file)\n",
    "\n",
    "system_prompt_for_classifier = group_classifier[\"prompt\"]\n",
    "\n",
    "with open(\"../prompts/memoryAssistant.yml\", \"r\") as file:\n",
    "    group_classifier = yaml.safe_load(file)\n",
    "\n",
    "system_prompt_for_assistant = group_classifier[\"prompt\"]\n",
    "\n",
    "with open(DB_INDEX_FILE_LOCAL_PATH, \"r\") as file:\n",
    "    metadata = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_messages_for_classifier(query, metadata):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt_for_classifier\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Query: ${query}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Metadata: ${metadata}\"\n",
    "        }        \n",
    "    ]\n",
    "\n",
    "def create_messages_for_assistant(query, memories):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt_for_assistant\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Query: ${query}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Memories: ${memories}\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"thinking_process\": \"The user's query is about memories related to vacations. Based on the provided metadata, the relevant category for this query is 'Areas' as it includes long-term responsibilities and interests, which can encompass travel and vacation plans. Specifically, the 'AREAS/TRAVELLING' files contain detailed information about various travel destinations and plans, which are directly related to the user's query about vacation memories.\",\n",
      "  \"keys\": [\n",
      "    \"AREAS/TRAVELLING/galicia\",\n",
      "    \"AREAS/TRAVELLING/roadmap_23-24\",\n",
      "    \"AREAS/TRAVELLING/travelling\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query = \"any memory about vacation\"\n",
    "completion = openAiClient.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    temperature=0,\n",
    "    stream=False,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    messages=create_messages_for_classifier(query, metadata)),\n",
    "\n",
    "completion_content = completion[0].choices[0].message.content\n",
    "print(completion_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"thinking_process\": \"The user is looking for memories related to vacations. I will search through the provided memories to find any relevant information about past or planned vacations. The memories include various travel destinations and a roadmap for travel plans in 2023-2024.\",\n",
      "  \"response\": \"Here are some vacation-related memories based on your notes:\\n\\n1. **Galicia**: You have a memory about visiting Galicia, specifically A Coruña, Anos, and A Eirita Candas Rosamonde.\\n\\n2. **Travel Roadmap 2023-2024**: You have planned several trips for the upcoming years:\\n   - **December 2023**: New York\\n   - **January 2024**: Salem\\n   - **February 2024**: Rome (twice)\\n   - **March 2024**: Åre/Trisil\\n   - **April 2024**: Cabin (possibly with Marta) and considering destinations like Sweden, Brazil, or France\\n   - **May 2024**: Taylor in Sweden\\n   - **June/July 2024**: Sweden\\n   - **July 2024**: Milan, Taylor, and Dolomites\\n   - **August 2024**: Argentina (Bayo)\\n   - **September 2024**: Menorca/Mallorca\\n\\n3. **Travel Destinations**: You have visited or plan to visit numerous places around the world, including Argentina, Spain, the UK, Italy, Austria, Germany, France, the Netherlands, Belgium, Czechia, Denmark, Norway, Finland, Estonia, Sweden, Australia, New Zealand, Fiji, Iceland, the United States, Bolivia, Ecuador, and Peru.\\n\\nWould you like more details on any specific trip or destination?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# parse the response in JSON and print the value of *data*\n",
    "import json\n",
    "\n",
    "\n",
    "keys = json.loads(completion_content)[\"keys\"]\n",
    "\n",
    "memories = []\n",
    "for key in keys:\n",
    "    memory_asset_path = os.path.join(DB_ROOT_LOCAL_PATH, key)\n",
    "    with open(memory_asset_path, \"r\") as file:\n",
    "        memory_asset_content = file.read()\n",
    "        memories.append({\n",
    "            \"path\": key,\n",
    "            \"content\": memory_asset_content\n",
    "        })\n",
    "\n",
    "memories_string = json.dumps(memories)\n",
    "\n",
    "completion = openAiClient.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    temperature=0,\n",
    "    stream=False,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    messages=create_messages_for_assistant(query, memories_string)),\n",
    "\n",
    "completion_content = completion[0].choices[0].message.content\n",
    "print(completion_content)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babel-api-32QMvPeQ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
